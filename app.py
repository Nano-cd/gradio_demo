# app.py
import gradio as gr
import pandas as pd
import threading
import time
import argparse
from pathlib import Path
import logging
import yaml

# ä»æˆ‘ä»¬çš„æ ¸å¿ƒè®­ç»ƒè„šæœ¬ä¸­å¯¼å…¥ main å‡½æ•°
from train_core import main as train_main

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# å…¨å±€å˜é‡æ¥è·Ÿè¸ªè®­ç»ƒçŠ¶æ€å’Œç»“æœè·¯å¾„
training_state = {
    "is_running": False,
    "results_dir": None,
    "thread": None,
    "args": None,
    "error_message": None
}


def find_latest_train_batch(results_dir):
    """è¾…åŠ©å‡½æ•°ï¼šæŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒæ‰¹æ¬¡å›¾åƒ"""
    if not results_dir or not results_dir.exists():
        return None
    image_files = sorted(results_dir.glob("train_batch*.jpg"))
    return str(image_files[-1]) if image_files else None


def run_training_and_update_ui(
        data_dir, output_dir, experiment_name, test_size,
        model_arch, epochs, batch_size, img_size, optimizer,
        learning_rate, dropout, seed
):
    """
    ä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œå¯åŠ¨è®­ç»ƒå¹¶æŒç»­ yield æ›´æ–°ç»™ UIã€‚
    ç›´æ¥æ˜¾ç¤ºYOLOç”Ÿæˆçš„å›¾åƒæ–‡ä»¶ï¼Œè€Œä¸æ˜¯åŠ¨æ€ç»˜åˆ¶ã€‚
    """
    if training_state["is_running"]:
        # å¦‚æœå·²ç»åœ¨è¿è¡Œï¼Œåªè¿”å›ä¸€ä¸ªçŠ¶æ€æ–‡æœ¬
        yield "ä¸€ä¸ªè®­ç»ƒä»»åŠ¡å·²åœ¨è¿è¡Œä¸­ã€‚", None, None, None, None, None, gr.Accordion(visible=False)
        return

    # 1. é‡ç½®çŠ¶æ€å¹¶æ„é€  args
    training_state.update({"is_running": True, "results_dir": None, "error_message": None})
    args = argparse.Namespace(
        data_dir=data_dir, output_dir=output_dir, experiment_name=experiment_name,
        test_size=test_size, model_arch=model_arch, epochs=epochs, batch_size=batch_size,
        img_size=img_size, optimizer=optimizer, learning_rate=learning_rate,
        dropout=dropout, seed=seed
    )
    training_state["args"] = args

    # 2. å®šä¹‰çº¿ç¨‹ç›®æ ‡å‡½æ•°
    def training_thread_target():
        try:
            save_dir = train_main(args)
            training_state["results_dir"] = Path(save_dir)
        except Exception as e:
            error_msg = f"è®­ç»ƒå‡ºé”™: {e}"
            logging.error(error_msg, exc_info=True)
            training_state["error_message"] = error_msg
        finally:
            training_state["is_running"] = False

    # 3. å¯åŠ¨è®­ç»ƒçº¿ç¨‹å¹¶è¿”å›åˆå§‹çŠ¶æ€
    training_state["thread"] = threading.Thread(target=training_thread_target)
    training_state["thread"].start()
    yield "è®­ç»ƒå·²å¼€å§‹ï¼Œæ­£åœ¨åˆå§‹åŒ–...", None, None, None, None, gr.Markdown(visible=False), gr.Accordion(visible=False)
    time.sleep(5)

    # 4. å¾ªç¯æ›´æ–° UI (åªæ›´æ–°å®æ—¶éƒ¨åˆ†)
    while training_state["thread"].is_alive():
        # ä¸»åŠ¨æŸ¥æ‰¾ç»“æœç›®å½•
        if training_state["results_dir"] is None:
            base_path = Path(args.output_dir) / args.experiment_name
            if base_path.exists():
                exp_dirs = sorted([d for d in base_path.iterdir() if d.is_dir()])
                if exp_dirs: training_state["results_dir"] = exp_dirs[-1]

        status_text = f"è®­ç»ƒæ­£åœ¨è¿›è¡Œä¸­... (Epochs: {epochs})"
        live_train_batch = find_latest_train_batch(training_state["results_dir"])

        # åœ¨å¾ªç¯ä¸­ï¼Œåªæ›´æ–°çŠ¶æ€å’Œå®æ—¶æ‰¹æ¬¡å›¾ï¼Œå…¶ä»–éƒ¨åˆ†ä¿æŒä¸å˜(None)
        yield status_text, live_train_batch, None, None, None, gr.Markdown(visible=False), gr.Accordion(visible=True,
                                                                                                        open=False)
        time.sleep(5)

    # 5. è®­ç»ƒç»“æŸåï¼Œå‘é€æœ€ç»ˆçŠ¶æ€
    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯å‘ç”Ÿ
    if training_state["error_message"]:
        final_status = f"ğŸ”´ **è®­ç»ƒå¤±è´¥**\n\né”™è¯¯ä¿¡æ¯: {training_state['error_message']}"
        yield final_status, None, None, None, None, gr.Markdown(visible=False), gr.Accordion(visible=False)
        return

    # å¦‚æœæˆåŠŸï¼Œå‡†å¤‡å¹¶æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    final_status = "âœ… **è®­ç»ƒæˆåŠŸå®Œæˆï¼**"
    results_dir = training_state["results_dir"]

    # å®šä¹‰è¦æŸ¥æ‰¾çš„å›¾åƒæ–‡ä»¶è·¯å¾„
    results_png = results_dir / "results.png" if results_dir else None
    confusion_matrix_png = results_dir / "confusion_matrix.png" if results_dir else None
    val_batch_jpg = results_dir / "val_batch0.jpg" if results_dir else None

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è®¾ä¸ºNone
    final_results_png = str(results_png) if results_png and results_png.exists() else None
    final_confusion_matrix_png = str(
        confusion_matrix_png) if confusion_matrix_png and confusion_matrix_png.exists() else None
    final_val_batch_jpg = str(val_batch_jpg) if val_batch_jpg and val_batch_jpg.exists() else None

    # ä¿ç•™æœ€åä¸€å¼ è®­ç»ƒæ‰¹æ¬¡å›¾
    final_train_batch = find_latest_train_batch(results_dir)

    # æ„å»ºç»“æœæ‘˜è¦ Markdown
    summary_text = "### è®­ç»ƒç»“æœæ€»ç»“\n\n"
    if results_dir and results_dir.exists():
        summary_text += f"- **ç»“æœä¿å­˜è·¯å¾„**: `{results_dir}`\n"
        best_model_path = results_dir / "weights" / "best.pt"
        if best_model_path.exists(): summary_text += f"- **æœ€ä½³æ¨¡å‹**: `{best_model_path}`\n"

        results_csv_path = results_dir / "results.csv"
        if results_csv_path.exists() and not pd.read_csv(results_csv_path).empty:
            df = pd.read_csv(results_csv_path)
            df.columns = df.columns.str.strip()
            final_metrics = df.iloc[-1]
            acc_top1 = final_metrics.get('metrics/accuracy_top1', 'N/A')
            if acc_top1 != 'N/A': acc_top1 = f"{acc_top1:.4f}"
            val_loss = final_metrics.get('val/cls_loss', 'N/A')
            if val_loss != 'N/A': val_loss = f"{val_loss:.4f}"
            summary_text += f"- **æœ€ç»ˆéªŒè¯é›†Top-1å‡†ç¡®ç‡**: {acc_top1}\n"
            summary_text += f"- **æœ€ç»ˆéªŒè¯é›†æŸå¤±**: {val_loss}\n"

    final_summary_md = gr.Markdown(value=summary_text, visible=True)

    # æœ€ç»ˆ yieldï¼Œæ›´æ–°æ‰€æœ‰ç»„ä»¶å¹¶å±•å¼€æŠ˜å é¢æ¿
    yield final_status, final_train_batch, final_results_png, final_confusion_matrix_png, final_val_batch_jpg, final_summary_md, gr.Accordion(
        visible=True, open=True)


# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(theme=gr.themes.Default(primary_hue="blue")) as demo:
    gr.Markdown("# ğŸš€ YOLOv8 åˆ†ç±»æ¨¡å‹è®­ç»ƒå™¨")
    with gr.Row():
        with gr.Column(scale=1):
            # ... (è¾“å…¥ç»„ä»¶éƒ¨åˆ†ä¸å˜) ...
            gr.Markdown("### 1. é…ç½®å‚æ•°")

            with gr.Accordion("æ•°æ®å’Œè·¯å¾„è®¾ç½®", open=True):
                data_dir_input = gr.Textbox(value="../dataset", label="æ•°æ®ç›®å½•")
                output_dir_input = gr.Textbox(value="runs", label="è¾“å‡ºç›®å½•")
                experiment_name_input = gr.Textbox(value="Tube_Classification_Gradio", label="å®éªŒåç§°")
                test_size_input = gr.Slider(0.1, 0.5, value=0.2, step=0.05, label="éªŒè¯é›†æ¯”ä¾‹")

            with gr.Accordion("æ¨¡å‹å’Œè®­ç»ƒè®¾ç½®", open=True):
                model_arch_input = gr.Dropdown(["yolov8n-cls", "yolov8s-cls", "yolov8m-cls"], value="yolov8s-cls",
                                               label="æ¨¡å‹æ¶æ„")
                epochs_input = gr.Slider(1, 100, value=10, step=1, label="è®­ç»ƒå‘¨æœŸ (Epochs)")
                batch_size_input = gr.Slider(2, 64, value=16, step=2, label="æ‰¹æ¬¡å¤§å° (Batch Size)")
                img_size_input = gr.Slider(128, 640, value=224, step=32, label="å›¾åƒå°ºå¯¸ (Image Size)")
                optimizer_input = gr.Dropdown(['SGD', 'Adam', 'AdamW'], value="Adam", label="ä¼˜åŒ–å™¨")
                learning_rate_input = gr.Number(value=0.001, label="å­¦ä¹ ç‡", precision=5)
                dropout_input = gr.Slider(0.0, 0.5, value=0.2, step=0.05, label="Dropoutç‡")
                seed_input = gr.Number(value=42, label="éšæœºç§å­", precision=0)

            start_button = gr.Button("ğŸš€ å¼€å§‹è®­ç»ƒ", variant="primary")

        with gr.Column(scale=2):
            gr.Markdown("### 2. å®æ—¶è®­ç»ƒç›‘æ§ä¸ç»“æœ")
            status_output = gr.Textbox(label="è®­ç»ƒçŠ¶æ€", interactive=False, value="ç­‰å¾…è®­ç»ƒå¼€å§‹...")

            # ç”¨äºå®æ—¶æ˜¾ç¤ºè®­ç»ƒæ‰¹æ¬¡çš„ç»„ä»¶
            train_batch_output = gr.Image(label="å®æ—¶è®­ç»ƒæ‰¹æ¬¡æ ·æœ¬ (train_batch)", type="filepath")

            # ç”¨äºæ˜¾ç¤ºæœ€ç»ˆç»“æœçš„æŠ˜å é¢æ¿
            with gr.Accordion("æœ€ç»ˆè®­ç»ƒç»“æœå›¾åƒ", visible=False, open=False) as results_accordion:
                with gr.Row():
                    results_png_output = gr.Image(label="æŸå¤±/æŒ‡æ ‡æ›²çº¿ (results.png)", type="filepath")
                    confusion_matrix_output = gr.Image(label="æ··æ·†çŸ©é˜µ (confusion_matrix.png)", type="filepath")
                val_batch_output = gr.Image(label="éªŒè¯æ‰¹æ¬¡æ ·æœ¬ (val_batch0.jpg)", type="filepath")

            summary_output = gr.Markdown(visible=False)

    # ç»‘å®šäº‹ä»¶
    all_inputs = [
        data_dir_input, output_dir_input, experiment_name_input, test_size_input,
        model_arch_input, epochs_input, batch_size_input, img_size_input,
        optimizer_input, learning_rate_input, dropout_input, seed_input
    ]
    all_outputs = [
        status_output,
        train_batch_output,
        results_png_output,
        confusion_matrix_output,
        val_batch_output,
        summary_output,
        results_accordion
    ]

    start_button.click(
        fn=run_training_and_update_ui,
        inputs=all_inputs,
        outputs=all_outputs
    )

if __name__ == "__main__":
    demo.launch()
